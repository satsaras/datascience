{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satsaras/datascience/blob/master/Easy_vs_Difficult_Articles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9t4rcsbIzTl",
        "colab_type": "code",
        "outputId": "81a084fd-d030-49ef-ea3a-368efa916ef9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import pickle\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "%matplotlib inline\n",
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn import decomposition, ensemble\n",
        "import numpy as np\n",
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_md\")\n",
        "import en_core_web_md\n",
        "nlp = en_core_web_md.load()\n",
        "from yellowbrick.text import FreqDistVisualizer\n",
        "import json\n",
        "from sklearn.svm import OneClassSVM\n",
        "import pandas as pd\n",
        "import torch\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO1YTj1HJIbx",
        "colab_type": "code",
        "outputId": "17ff31be-2d34-49e0-cf9e-cdbc1d039299",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHMpaQ0P78Au",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('drive/My Drive/Data/Cochrane 5029 articles.pkl','rb') as f:\n",
        "    data=pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuKuoAoG8Mb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5C7L8Ur-e36",
        "colab_type": "code",
        "outputId": "c141054c-d2aa-417c-9438-e689b9fdc8f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_SI4SXI-ocg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "medical_stopwords=['participant','treatment','compare','effect','quality','risk','low','outcome','people','intervention','report', \n",
        " 'search','difference','group','datum','control','assess','patient','woman','adverse','analysis','reduce','placebo','high','bias',\n",
        "'pain','child','therapy','method','event','conclusion','clinical','disease','increase','author','drug','rate','criterion','number',\n",
        "'follow','need','care','improve','different','background','identify','blood','rct','surgery','treat','year','benefit','selection', \n",
        " 'small','month','mean','significant','life','adult','collection','moderate','type','effective','receive','cause','infant','provide', \n",
        " 'evaluate','measure','symptom','day','time','confidence','week','overall','prevent','primary','antibiotic','health','age','interval',\n",
        "'comparison','independently','death','standard','term','involve','associate','update','randomised','available','non','effectiveness',\n",
        "'birth','total','inclusion','certainty','suggest','randomise','extract','support','test','complication','ratio','relevant','exercise',\n",
        "'base','information','oral','reduction','change','hospital','important','common','reference','level','publish','research','conduct',\n",
        "'function','additional','make','acute','efficacy','determine','pressure','safety','improvement','combination','perform','surgical',\n",
        "'medication','require','lead','early','consider','question','finding','key','range','duration','database','unclear','clear','characteristic',\n",
        "'condition','cell','dose','issue','uncertain','severe','problem','large','list','aim','individual','design','current','procedure',\n",
        "'long','score','affect','help','possible','contact','secondary','date','harm','likely','develop','preterm','assessment','stroke',\n",
        "'agent','know','new','good','disorder','management','combine','methodological','strategy','survival','experience','insufficient',\n",
        "'heart','similar','significantly','little','technique','approach','incidence','regard','estimate','examine','remain','activity','training',\n",
        "'occur','failure','investigate','single','medical','undergo','work','mg','lack','physical','loss','major','seizure','population','form',\n",
        "'heterogeneity','weight','vitamin','decrease','setting','body','short','present','size','main','limited','period','impact','active',\n",
        "'eligible','ongoing','look','cost','usual','injury','case','practice','medicine','potential','beneficial','hour','meet','prevention',\n",
        "'factor','country','systematic','probably','acid','model','statistically','programme','great','language','appear','pool','addition',\n",
        "'stay','future','labour','point','morbidity','wound','limit','exclude','healthcare','daily','clinically','add','diagnosis','poor','average','way',\n",
        "'old','recommend','article','scale','general','study','include','trial','result','evidence','use','review','abstract','objective','conclusion','cochrane','register','medline','embase','central','cinahl','extract','search']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwF_rdSx_K_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "difficult_Articles=pd.DataFrame(data.iloc[:,1])\n",
        "easy_Articles=pd.DataFrame(data.iloc[:,2])\n",
        "easy_Articles=easy_Articles.rename(columns={'Plain Language Summary':'Abstract'})\n",
        "easy_Articles['Is_Difficult']=0\n",
        "difficult_Articles['Is_Difficult']=1\n",
        "full_Articles=difficult_Articles.append(easy_Articles)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI2I3HQTdqC1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def PreProcess_Article(df):\n",
        "    #Remove words bery specific to Difficult articles to reduce bias\n",
        "    df.iloc[:,0]=df.iloc[:,0].str.lower()\n",
        "    df.iloc[:,0] = [re.sub('background\\n',' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub('main results\\n' ,' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub('objectives\\n' ,' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub('data collection and analysis\\n' ,' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub(\"authors' conclusions\\n\" ,' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub(\"selection criteria\\n\" ,' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub(\"search methods\\n\" ,' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub(\"key results\\n\" ,' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub(\"certainty of evidence\\n\" ,' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub(\"study characteristics\\n\" ,' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub(\"review question\\n\" ,' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub(\"conclusions\\n\" ,' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub('\\n',' ', i) for i in df.iloc[:,0]]\n",
        "    #Remove digits and %\n",
        "    df.iloc[:,0] = [re.sub(r'\\d+',' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub(r'%',' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub(r'CI',' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub(r'\\([^)]*\\)',' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub(r'mg/dL',' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub(r'I²',' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub(r'P',' ', i) for i in df.iloc[:,0]]\n",
        "    # REmove special symbols\n",
        "    df.iloc[:,0] = [re.sub(r\"[#|\\.|_|\\^|\\$|\\&|=|;|,|‐|(|)|//]\",' ', i) for i in df.iloc[:,0]]\n",
        "    #Remove multiple spaces\n",
        "    df.iloc[:,0] = [re.sub(' +',' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0]=lemmatization(df)\n",
        "    df.iloc[:,0] = df.iloc[:,0].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "    df.iloc[:,0] = df.iloc[:,0].apply(lambda x: ' '.join([word for word in x.split() if word not in (medical_stopwords)]))\n",
        "    \n",
        "    return(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dX4R_fkvduxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lemmatization(df, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    texts_out = []\n",
        "    for sent in df.iloc[:,0]:\n",
        "        doc = nlp(sent)\n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    for i in range(len(df)):\n",
        "        df.iloc[i,0]=\" \".join([word for word in texts_out[i]])\n",
        "    return(df.iloc[:,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRK4fOTWd0cK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_Articles=PreProcess_Article(pd.DataFrame(full_Articles))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzfqSrHIeVTf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1ef05cf7-9f7f-4fe1-f95f-cae4da8dce28"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, GRU\n",
        "from keras.models import Sequential"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mOY01l0d2uX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer=Tokenizer(num_words=16000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TZpeu3jjR9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data,test_data = train_test_split(full_Articles,train_size=0.7,random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0MTZrUMjT_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_LSTM=train_data['Abstract']\n",
        "tokenizer.fit_on_texts(list(train_data['Abstract']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTFY8CsRkCMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = train_data['Is_Difficult']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55mcubhmjXmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_LSTM = tokenizer.texts_to_sequences(X_LSTM)\n",
        "X_LSTM = pad_sequences(X_LSTM, maxlen=16000)\n",
        "Y=to_categorical(y)\n",
        "test_X = tokenizer.texts_to_sequences(test_data['Abstract'])\n",
        "test_X = pad_sequences(test_X, maxlen=16000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju5aT2enjjmo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings_idx={}\n",
        "f=open(\"drive/My Drive/Data/glove.6B.50d.txt\", \"r\")\n",
        "for line in f:\n",
        "    values=line.split()\n",
        "    word=values[0]\n",
        "    coefs=np.asarray(values[1:],dtype='float32')\n",
        "    embeddings_idx[word]=coefs\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTTCNbDQkP90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim=50\n",
        "total_words=16000\n",
        "i=0\n",
        "embedding_matrix=np.zeros((total_words,embedding_dim))\n",
        "for word in tokenizer.word_index.keys():\n",
        "    if i<total_words:\n",
        "        embedding_vec=embeddings_idx.get(word)\n",
        "        if embedding_vec is not None:\n",
        "            embedding_matrix[i]=embedding_vec\n",
        "    i+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H087wK54k2PB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "6fb522cc-91e3-4a20-cdfb-e913c4ea1d83"
      },
      "source": [
        "\n",
        "model=Sequential()\n",
        "model.add(Embedding(total_words, embedding_dim, input_length=16000))\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(GRU(196))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "print(model.summary())\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "             optimizer='adam', \n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 16000, 50)         800000    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 16000, 50)         0         \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 196)               145236    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 394       \n",
            "=================================================================\n",
            "Total params: 945,630\n",
            "Trainable params: 945,630\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQqS0avEk5AS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "73db8af1-356c-40ea-e8df-a3de053dc844"
      },
      "source": [
        "\n",
        "batch_size = 100\n",
        "model.fit(X_train, Y_train, epochs = 5, batch_size=batch_size,validation_data=(X_val,Y_val))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 5280 samples, validate on 1760 samples\n",
            "Epoch 1/5\n",
            "5280/5280 [==============================] - 2663s 504ms/step - loss: 0.7285 - acc: 0.5525 - val_loss: 0.6600 - val_acc: 0.5898\n",
            "Epoch 2/5\n",
            "5280/5280 [==============================] - 2571s 487ms/step - loss: 0.5469 - acc: 0.7396 - val_loss: 0.4440 - val_acc: 0.8091\n",
            "Epoch 3/5\n",
            "5280/5280 [==============================] - 2655s 503ms/step - loss: 0.2791 - acc: 0.8854 - val_loss: 0.3101 - val_acc: 0.9045\n",
            "Epoch 4/5\n",
            "5280/5280 [==============================] - 2595s 491ms/step - loss: 0.1136 - acc: 0.9619 - val_loss: 0.2392 - val_acc: 0.9352\n",
            "Epoch 5/5\n",
            "5280/5280 [==============================] - 2590s 491ms/step - loss: 0.0454 - acc: 0.9869 - val_loss: 0.2179 - val_acc: 0.9426\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f05a485a3c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYo-MsaclMbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, Y_train, Y_val = train_test_split(X_LSTM, Y, test_size=0.25, random_state=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz7FdNfGk81Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pubmed_data=pd.read_csv('drive/My Drive/Data/Pubmed Data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZfBDfslo2yh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_save_name = 'classifier_easy_difficult'\n",
        "path = \"drive/My Drive/{model_save_name}\" \n",
        "torch.save(model, path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbjTkBr2qUFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def PreProcess_Article_test(df):\n",
        "    #Remove words bery specific to Difficult articles to reduce bias\n",
        "    df.iloc[:,0]=df.iloc[:,0].str.lower()\n",
        "    df.iloc[:,0] = [re.sub(r'abstract',' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub('abstractbackground:',' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub('main results' ,' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub('abstractobjective:' ,' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub('abstractrationale:' ,' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub('abstractpurpose:' ,' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub('abstractaims:' ,' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub('abstractintroduction:' ,' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub('data collection and analysis' ,' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub(\"authors' conclusions\" ,' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub(\"selection criteria\" ,' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub(\"methods:\" ,' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub(\"results:\" ,' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub(\"certainty of evidence\" ,' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub(\"study characteristics\" ,' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub(\"review question\" ,' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub(\"conclusion:\" ,' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub('\\n',' ', i) for i in df.iloc[:,0]]\n",
        "    #Remove digits and %\n",
        "    df.iloc[:,0] = [re.sub(r'\\d+',' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub(r'%',' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub(r'CI',' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub(r'\\([^)]*\\)',' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub(r'mg/dL',' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub(r'I²',' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = [re.sub(r'P',' ', i) for i in df.iloc[:,0]]\n",
        "    # REmove special symbols\n",
        "    df.iloc[:,0] = [re.sub(r\"[#|\\.|_|\\^|\\$|\\&|=|;|:|,|‐|(|)|//]\",' ', i) for i in df.iloc[:,0]]\n",
        "    #Remove multiple spaces\n",
        "    df.iloc[:,0] = [re.sub(' +',' ', i) for i in df.iloc[:,0]]\n",
        "    df.iloc[:,0] = df.iloc[:,0].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "    df.iloc[:,0] = df.iloc[:,0].apply(lambda x: ' '.join([word for word in x.split() if word not in (medical_stopwords)]))\n",
        "    df.iloc[:,0]=lemmatization(df)\n",
        "    return(df)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZVxbb6LqiyN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pubmed_data_preproc=PreProcess_Article_test(pubmed_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTyN3gcIqq7c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pubmed_data_preproc_x = tokenizer.texts_to_sequences(pubmed_data_preproc['Abstract'])\n",
        "pubmed_data_preproc_x = pad_sequences(pubmed_data_preproc_x, maxlen=16000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mkzz7OvZq_Xy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pubmed_pred=np.argmax(model.predict(pubmed_data_preproc_x),axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIbvnVjarQtD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc5258be-76a3-4c25-c5a8-65320671903f"
      },
      "source": [
        "np.mean(pubmed_pred==pubmed_data['Is Difficult'].values)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5130434782608696"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrkMEDDQrj_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}